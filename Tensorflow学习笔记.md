# Tensorflow学习笔记



## 搭建神经网络

BATCH_SIZE从8调到12的时候 就已经是过大 使得神经网络噎到. 最后结果的偏差变大了

训练次数的增加会使得偏差变小



反向传播训练方法：

梯度向下

Momentum优化器

Adam优化器



测试 在steps=6000 BATCHSIZE=8下

Momentum优化器 > Adam优化器 > 梯度向下



在梯度向下的方法下 把学习率从0.001提升到0.005后 偏差大幅减少



搭建神经网络的八股

**准备、前传、反传、迭代**



准备数据集

定义输入、参数和输出

定义损失函数、反向传播方法

生成会话，训练

